{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dreaming_lewis_carrol.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNHIoW3Ed5U+Dikm/4+8HXH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"B0m32aJBac2C","executionInfo":{"status":"ok","timestamp":1605232354920,"user_tz":480,"elapsed":1732,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDhPy491cYuK","executionInfo":{"status":"ok","timestamp":1605232354926,"user_tz":480,"elapsed":1734,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["# consistent and stable output\n","np.random.seed(0)\n","tf.random.set_seed(0)\n","\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_opg6cXheEbM"},"source":["# Load the Data"]},{"cell_type":"code","metadata":{"id":"1xY3Y_n1feDa","executionInfo":{"status":"ok","timestamp":1605232355109,"user_tz":480,"elapsed":1907,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"41393dee-0f6c-4769-fe8f-ebb878f5ec33","colab":{"base_uri":"https://localhost:8080/"}},"source":["alice_url = \"https://raw.githubusercontent.com/grbruns/cst383/master/alice.txt\"\n","filepath = keras.utils.get_file(\"alice.txt\", alice_url)\n","with open(filepath) as f:\n","    alice_text = f.read()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://raw.githubusercontent.com/grbruns/cst383/master/alice.txt\n","155648/147733 [===============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LLmtFXoGgMnA","executionInfo":{"status":"ok","timestamp":1605232355110,"user_tz":480,"elapsed":1899,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"3275bdbb-eb8a-4433-95b8-263e1591ad98","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(alice_text[:150])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["ï»¿\n","ALICE'S ADVENTURES IN WONDERLAND\n","\n","Lewis Carroll\n","\n","CHAPTER I. Down the Rabbit-Hole\n","\n","Alice was beginning to get very tired of sitting by her sister on \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_BBjOIjGhz1W","executionInfo":{"status":"ok","timestamp":1605232355350,"user_tz":480,"elapsed":2137,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(alice_text)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWnwC9qriLZr","executionInfo":{"status":"ok","timestamp":1605232355351,"user_tz":480,"elapsed":2130,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"7bdfed5a-cf9e-4cc8-d145-90b1f0fc4b7d","colab":{"base_uri":"https://localhost:8080/"}},"source":["tokenizer.texts_to_sequences([\"First\"])"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[22, 6, 10, 9, 3]]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"t9XecPEyiZ0g","executionInfo":{"status":"ok","timestamp":1605232355351,"user_tz":480,"elapsed":2122,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"3be395a1-f8bd-4aba-ef04-34a0648a9879","colab":{"base_uri":"https://localhost:8080/"}},"source":["tokenizer.sequences_to_texts([[22, 6, 10, 9, 3]])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['f i r s t']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"0afMrKvqi9u-","executionInfo":{"status":"ok","timestamp":1605232355352,"user_tz":480,"elapsed":2115,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"89455838-7009-48f2-9e3e-5bb8e59ac328","colab":{"base_uri":"https://localhost:8080/"}},"source":["max_id = len(tokenizer.word_index) # number of distinct characters\n","dataset_size = tokenizer.document_count # total number of characters\n","print(max_id)\n","print(dataset_size)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["44\n","144395\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JYHIgZK92KV5","executionInfo":{"status":"ok","timestamp":1605232360710,"user_tz":480,"elapsed":7471,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["[encoded] = np.array(tokenizer.texts_to_sequences([alice_text])) - 1\n","train_size = dataset_size * 90 // 100\n","dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXsh5g4t23rI","executionInfo":{"status":"ok","timestamp":1605232360711,"user_tz":480,"elapsed":7470,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["n_steps = 100\n","window_length = n_steps + 1 # target = input shifted 1 character ahead\n","dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0sJlW303Mai","executionInfo":{"status":"ok","timestamp":1605232360712,"user_tz":480,"elapsed":7470,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["dataset = dataset.flat_map(lambda window: window.batch(window_length))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"EzfdSfcUq4KZ","executionInfo":{"status":"ok","timestamp":1605232360712,"user_tz":480,"elapsed":7468,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["batch_size = 128\n","dataset = dataset.shuffle(10000).batch(batch_size)\n","dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KYgc-O-rIS2","executionInfo":{"status":"ok","timestamp":1605232360846,"user_tz":480,"elapsed":7600,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCb3UNESr5eK","executionInfo":{"status":"ok","timestamp":1605232360849,"user_tz":480,"elapsed":7600,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["dataset = dataset.prefetch(1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyC9RUE5r9G5","executionInfo":{"status":"ok","timestamp":1605232362026,"user_tz":480,"elapsed":8769,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"d6db7f0c-443e-478c-a9d7-8e317835d5ae","colab":{"base_uri":"https://localhost:8080/"}},"source":["for X_batch, Y_batch in dataset.take(1):\n","  print(X_batch.shape, Y_batch.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(128, 100, 44) (128, 100)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rMkhlS4M22_1"},"source":["# Creating and Training the Model"]},{"cell_type":"code","metadata":{"id":"0r_sKWjksJoH","executionInfo":{"status":"ok","timestamp":1605234333705,"user_tz":480,"elapsed":1980440,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"7733f7e1-bb33-4878-bc98-b755592b1d40","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = keras.models.Sequential([\n","  keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n","  keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n","  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))                                 \n","])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=3)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","1015/1015 [==============================] - 646s 637ms/step - loss: 2.0442\n","Epoch 2/3\n","1015/1015 [==============================] - 661s 651ms/step - loss: 1.5521\n","Epoch 3/3\n","1015/1015 [==============================] - 658s 648ms/step - loss: 1.4362\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8hL4CBHNYe8O"},"source":["# Using the Model to Generate Text"]},{"cell_type":"markdown","metadata":{"id":"8Tll9g136f7Y"},"source":["With this function, we can preprocess the text to feed it to the model"]},{"cell_type":"code","metadata":{"id":"D0fvqcvQYeNC","executionInfo":{"status":"ok","timestamp":1605234333708,"user_tz":480,"elapsed":1980441,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["def preprocess(texts):\n","  X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n","  return tf.one_hot(X, max_id)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N13mYI5x7Fgk"},"source":["Here we can use the model to try and predict the next letter."]},{"cell_type":"code","metadata":{"id":"7N2EegozZHEV","executionInfo":{"status":"ok","timestamp":1605234334226,"user_tz":480,"elapsed":1980950,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"77b3391c-0faf-488c-9577-d1395221e5b5","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["X_new = preprocess(['How are yo'])\n","Y_pred = np.argmax(model.predict(X_new), axis=-1)\n","tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # First sentence, last character"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'u'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"YR-bSmUj7_dh"},"source":["With the next_char and complete_text function, we can generate some text that is like from Alice text."]},{"cell_type":"code","metadata":{"id":"g484-1RfZplb","executionInfo":{"status":"ok","timestamp":1605234334228,"user_tz":480,"elapsed":1980950,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["def next_char(text, temperature=1):\n","  X_new = preprocess([text])\n","  y_proba = model.predict(X_new)[0, -1:, :]\n","  rescaled_logits = tf.math.log(y_proba) / temperature\n","  char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n","  return tokenizer.sequences_to_texts(char_id.numpy())[0]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_UZRup6aJUY","executionInfo":{"status":"ok","timestamp":1605234334230,"user_tz":480,"elapsed":1980943,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"cf34f161-9f3e-42c6-b1bd-54fdf90fde98","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["next_char('how are yo', temperature=1)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'u'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"O0-3VetaaP9w","executionInfo":{"status":"ok","timestamp":1605234334232,"user_tz":480,"elapsed":1980942,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["def complete_text(text, n_chars=50, temperature=1):\n","  for _ in range(n_chars):\n","    text += next_char(text, temperature)\n","  return text"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5O5hTW0f_tIQ"},"source":["# Creative Outputs "]},{"cell_type":"markdown","metadata":{"id":"tPJ2RaSPD6qu"},"source":["The model is generating some interesting text, not making too much sense however."]},{"cell_type":"code","metadata":{"id":"Vc_8uA7qC1jQ","executionInfo":{"status":"ok","timestamp":1605234340047,"user_tz":480,"elapsed":1986750,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"ffdf81eb-05dc-4316-de7a-084ccb52e13d","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('hello', temperature=1))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["hellow.'\n","\n","'oh, and ale then, out to even it,' said the \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cnWl3dYtC965","executionInfo":{"status":"ok","timestamp":1605234340048,"user_tz":480,"elapsed":1986743,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"fe0dae09-4110-4e36-a598-739d8b626f81","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('there', temperature=1))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["there' alice squeaked alice dansiday: 'i never followin\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oT8w9PWiDNgH","executionInfo":{"status":"ok","timestamp":1605234345334,"user_tz":480,"elapsed":1992022,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"d4fb5744-8e68-46b1-f044-a78b8fea3032","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('the hole', temperature=1))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["the holent.\n","\n","alice was no moment her like of the opters, a\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xHnGj_PujFzn"},"source":["# Experimenting with the model"]},{"cell_type":"markdown","metadata":{"id":"KKDFFx96pcO3"},"source":["The model from the Geron text seems to only use two layers that are GRU. I want to see how the model performs as well with only using a subset of the alice text. This model will only use the first half of the text for faster training and faster tweaking. I will also lower number of steps to see if we can improve the output. For this experiment, I will change the optimizer to RMSProp as well"]},{"cell_type":"code","metadata":{"id":"As6L6wd8FLzx","executionInfo":{"status":"ok","timestamp":1605234345335,"user_tz":480,"elapsed":1992021,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["alice_shorter_text = alice_text[:len(alice_text) // 2]\n","\n","tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(alice_shorter_text)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"sBloWHlhHEyL","executionInfo":{"status":"ok","timestamp":1605234345335,"user_tz":480,"elapsed":1992013,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"b93e9f59-be8c-44ea-e07a-29b5ce926293","colab":{"base_uri":"https://localhost:8080/"}},"source":["max_id = len(tokenizer.word_index) # number of distinct characters\n","dataset_size = tokenizer.document_count # total number of characters\n","print(max_id)\n","print(dataset_size)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["42\n","72197\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xm7R6r0jHRil","executionInfo":{"status":"ok","timestamp":1605234345336,"user_tz":480,"elapsed":1992007,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"1eaeaef7-fac8-40f2-87ba-65221df4a4b2","colab":{"base_uri":"https://localhost:8080/"}},"source":["[encoded] = np.array(tokenizer.texts_to_sequences([alice_shorter_text])) - 1\n","train_size = dataset_size * 90 // 100\n","dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n","\n","n_steps = 50\n","window_length = n_steps + 1 # target = input shifted 1 character ahead\n","dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)\n","\n","dataset = dataset.flat_map(lambda window: window.batch(window_length))\n","\n","batch_size = 64\n","dataset = dataset.shuffle(10000).batch(batch_size)\n","dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n","\n","dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n","\n","dataset = dataset.prefetch(1)\n","\n","for X_batch, Y_batch in dataset.take(1):\n","  print(X_batch.shape, Y_batch.shape)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["(64, 50, 42) (64, 50)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KsURO5NNjHwm","executionInfo":{"status":"ok","timestamp":1605235309467,"user_tz":480,"elapsed":2956129,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"c86f3860-09e5-4891-ee6f-07fba31a8d17","colab":{"base_uri":"https://localhost:8080/"}},"source":["keras.backend.clear_session()\n","\n","model = keras.models.Sequential([\n","  keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id], dropout=0.2, recurrent_dropout=0.2),\n","  keras.layers.GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n","  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))                                 \n","])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=3)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Epoch 1/3\n","1015/1015 [==============================] - 320s 315ms/step - loss: 2.1407\n","Epoch 2/3\n","1015/1015 [==============================] - 320s 316ms/step - loss: 1.6789\n","Epoch 3/3\n","1015/1015 [==============================] - 321s 316ms/step - loss: 1.5411\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RoI31edbSt_m","executionInfo":{"status":"ok","timestamp":1605235309929,"user_tz":480,"elapsed":2956583,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"ef2594a8-7194-4bc3-c705-12a3d2401b9a","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["next_char('hol', temperature=1)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'d'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"xN4Cz5BYVDCB","executionInfo":{"status":"ok","timestamp":1605235313043,"user_tz":480,"elapsed":2959688,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"62873c32-a605-4308-d63a-d0edeb657910","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('h', temperature=1))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["he e\"cid a was glows here, alice, 'intwif, was she \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DBu6W2A5pt3z"},"source":["An interesting thing that the model from the Geron text is that it uses dropout and recurrent dropout. I wonder how the model will be without these hyperparameters. We can see that without dropout, training is a lot faster since the model can use cuDNN kernal layers."]},{"cell_type":"code","metadata":{"id":"KnF4Op-UV2EU","executionInfo":{"status":"ok","timestamp":1605235313808,"user_tz":480,"elapsed":2960451,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}}},"source":["keras.backend.clear_session()\n","\n","model = keras.models.Sequential([\n","  keras.layers.LSTM(128, return_sequences=True, input_shape=[None, max_id]),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))                                 \n","])"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnCFeZVjWzA5","executionInfo":{"status":"ok","timestamp":1605235410512,"user_tz":480,"elapsed":3057146,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"1abd58f8-6afc-462e-9b91-49d8cb32c27e","colab":{"base_uri":"https://localhost:8080/"}},"source":["model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=5)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1015/1015 [==============================] - 17s 17ms/step - loss: 2.8960\n","Epoch 2/5\n","1015/1015 [==============================] - 17s 17ms/step - loss: 2.1301\n","Epoch 3/5\n","1015/1015 [==============================] - 17s 17ms/step - loss: 1.8346\n","Epoch 4/5\n","1015/1015 [==============================] - 18s 17ms/step - loss: 1.6722\n","Epoch 5/5\n","1015/1015 [==============================] - 18s 17ms/step - loss: 1.5504\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IyFFxqEtmw4m"},"source":["Using LTSM insread of GRU seems to generate interesting text."]},{"cell_type":"code","metadata":{"id":"OOlCI5JJm6Dd","executionInfo":{"status":"ok","timestamp":1605235411575,"user_tz":480,"elapsed":3058197,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"129d312f-fedb-44fe-84f1-e920269c953a","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["next_char('hol', temperature=1)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'e'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"MszERYhNmp7h","executionInfo":{"status":"ok","timestamp":1605235415182,"user_tz":480,"elapsed":3061793,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"7a946919-e6f8-4cdd-a74e-e1a351cab3f5","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('hol', temperature=1))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["hold\n","shusks bat unce! the rawt atcile withto dich on \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-9FvYLAt8RL9"},"source":["Now i want to see how the model with GRU will perform without dropout and recurrent dropout. Training is much faster since the model fits the cuDNN kernal requirements"]},{"cell_type":"code","metadata":{"id":"s8nmLADe8QUt","executionInfo":{"status":"ok","timestamp":1605235523139,"user_tz":480,"elapsed":3169741,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"a27846bc-9752-481f-f50f-7e1f34dca3e2","colab":{"base_uri":"https://localhost:8080/"}},"source":["keras.backend.clear_session()\n","\n","model = keras.models.Sequential([\n","  keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n","  keras.layers.GRU(128, return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))                                 \n","])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=10)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 1.8314\n","Epoch 2/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 1.1375\n","Epoch 3/10\n","1015/1015 [==============================] - 11s 10ms/step - loss: 0.8473\n","Epoch 4/10\n","1015/1015 [==============================] - 11s 10ms/step - loss: 0.6699\n","Epoch 5/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 0.5611\n","Epoch 6/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 0.4918\n","Epoch 7/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 0.4469\n","Epoch 8/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 0.4139\n","Epoch 9/10\n","1015/1015 [==============================] - 10s 10ms/step - loss: 0.3910\n","Epoch 10/10\n","1015/1015 [==============================] - 11s 11ms/step - loss: 0.3740\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c160idUG9Qki","executionInfo":{"status":"ok","timestamp":1605235523680,"user_tz":480,"elapsed":3170273,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"51ac3e9a-5cd6-4f83-a8e9-014391176143","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["next_char('nam', temperature=1)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'e'"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"eY76seLQ9Y2s","executionInfo":{"status":"ok","timestamp":1605235526273,"user_tz":480,"elapsed":3172857,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"72d9e388-8241-4fef-e47f-ceaed5ab5f48","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('i am a ', temperature=1))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["i am a dear little she\n","was moving them about as she could\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MfdnN16A9udH"},"source":["In this last model that I want to experiment with, I will use both layers (GRU and LSTM) and see how this one performs on predicting and generating text."]},{"cell_type":"code","metadata":{"id":"A1mwcgdj9t_Z","executionInfo":{"status":"ok","timestamp":1605235755756,"user_tz":480,"elapsed":3402331,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"7ce3e566-6a80-49bf-9deb-ea5e970c91aa","colab":{"base_uri":"https://localhost:8080/"}},"source":["keras.backend.clear_session()\n","\n","model = keras.models.Sequential([\n","  keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.GRU(128, return_sequences=True),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.GRU(128, return_sequences=True),\n","  keras.layers.LSTM(128, return_sequences=True),\n","  keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))                                 \n","])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n","history = model.fit(dataset, steps_per_epoch=train_size // batch_size, epochs=10)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 3.0155\n","Epoch 2/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 2.6061\n","Epoch 3/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 1.6028\n","Epoch 4/10\n","1015/1015 [==============================] - 22s 21ms/step - loss: 1.2600\n","Epoch 5/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 1.0265\n","Epoch 6/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 0.8503\n","Epoch 7/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 0.7131\n","Epoch 8/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 0.6110\n","Epoch 9/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 0.5347\n","Epoch 10/10\n","1015/1015 [==============================] - 22s 22ms/step - loss: 0.4787\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s3GSqkrwTJJP","executionInfo":{"status":"ok","timestamp":1605236132659,"user_tz":480,"elapsed":2517,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"0a7b7397-df99-4d40-fe07-d23115c4b29d","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('pa', temperature=1))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["pair, but at the\n","hoar to come in amring her nint, an\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o153G-tfTQ-K","executionInfo":{"status":"ok","timestamp":1605236154026,"user_tz":480,"elapsed":2275,"user":{"displayName":"Jacob Ortiz","photoUrl":"","userId":"02939833757379365112"}},"outputId":"01c4a433-95a6-44d2-e0b1-612bb382d54b","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(complete_text('she', temperature=1))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["shes with in her high) at the sides of\n","west her head \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O802DwdXPryl"},"source":["# Paragraph about Lewis Carrol"]},{"cell_type":"markdown","metadata":{"id":"9OwWoERQPveZ"},"source":["Lewis Carroll was an English Novelist and a poet. He was also a lecturer in mathematics at Oxford. He is also best known for his work as the author of the children's book Alice's Adventures in Wonderland, as well as the sequel Through the Looking-Glass. Not only being amathematics lecturere, he was also an avid photographer and wrote essays, political pamphlets and poetry."]}]}